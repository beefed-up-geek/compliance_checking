{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "43d1f8b676b94b20ab594d6af299c30b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_790249fd776e4dceb9027528eac218e9",
              "IPY_MODEL_c7677db32e4640278056651b3081f05e",
              "IPY_MODEL_c1ee22a250a743558cfd93de3a804fac"
            ],
            "layout": "IPY_MODEL_1305d722bba442a1b8f5dc36a44c1e82"
          }
        },
        "790249fd776e4dceb9027528eac218e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21a0178c8770419c8689e2319987a77c",
            "placeholder": "​",
            "style": "IPY_MODEL_ed6b0380ae1b49ff883179546ac9a330",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c7677db32e4640278056651b3081f05e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0378e4d66ed4f168442646bcac632bd",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e82f75e27d0e4cff823708b9bec6499b",
            "value": 4
          }
        },
        "c1ee22a250a743558cfd93de3a804fac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de2dcff09c57447e852504be49f36bd7",
            "placeholder": "​",
            "style": "IPY_MODEL_c6d3a2ac646e44aa967c0fb872067192",
            "value": " 4/4 [00:04&lt;00:00,  1.22s/it]"
          }
        },
        "1305d722bba442a1b8f5dc36a44c1e82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21a0178c8770419c8689e2319987a77c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed6b0380ae1b49ff883179546ac9a330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0378e4d66ed4f168442646bcac632bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e82f75e27d0e4cff823708b9bec6499b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de2dcff09c57447e852504be49f36bd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6d3a2ac646e44aa967c0fb872067192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 필수 패키지 설치"
      ],
      "metadata": {
        "id": "IsOywGRyuNXH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tMWYw8yut-pb"
      },
      "outputs": [],
      "source": [
        "!pip -q install transformers accelerate torch openai python-dotenv pandas tqdm requests numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 하이퍼파라미터"
      ],
      "metadata": {
        "id": "HqMJPQby3obw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 사용자 설정 (여기를 바꿔 쓰세요) ----------\n",
        "THRESHOLD = None     # 코사인 유사도 임계값\n",
        "TOP_K = 8            # 상위 몇 개의 관련 조항을 정보로 넣을지\n",
        "EMBED_MODEL = \"text-embedding-3-large\""
      ],
      "metadata": {
        "id": "vLyy-ig23p7S"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 설정 & 유틸"
      ],
      "metadata": {
        "id": "7TUlAAB1uOsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from typing import List, Dict, Any, Tuple\n",
        "\n",
        "from tqdm import tqdm\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "\n",
        "# 로컬 저장 옵션\n",
        "SAVE_OUTPUT_CSV = True\n",
        "OUTPUT_CSV_PATH = \"gdpr_violation_predictions.csv\"\n",
        "\n",
        "# LLM 모델 (Qwen 권장)\n",
        "MODEL_ID = \"Qwen/Qwen2-7B-Instruct\"  # 대안: \"google/gemma-7b-it\", \"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "\n",
        "# 생성 파라미터\n",
        "GEN_ARGS = dict(\n",
        "    max_new_tokens=8,\n",
        "    do_sample=False,\n",
        "    temperature=0.0,\n",
        ")\n",
        "\n",
        "# ---------- 환경 변수 ----------\n",
        "#load_dotenv()\n",
        "#OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "OPENAI_API_KEY = \"\"\n",
        "if not OPENAI_API_KEY:\n",
        "    raise RuntimeError(\"환경변수 OPENAI_API_KEY가 설정되지 않았습니다. .env 파일을 확인하세요.\")\n",
        "\n",
        "# ---------- OpenAI Embeddings ----------\n",
        "from openai import OpenAI\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "\n",
        "def cosine_sim(a: np.ndarray, b: np.ndarray) -> float:\n",
        "    denom = (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "    if denom == 0:\n",
        "        return 0.0\n",
        "    return float(np.dot(a, b) / denom)\n",
        "\n",
        "def get_embedding(text: str, model: str = EMBED_MODEL, max_retries: int = 5) -> List[float]:\n",
        "    text = (text or \"\").strip()\n",
        "    last_err = None\n",
        "    for attempt in range(1, max_retries + 1):\n",
        "        try:\n",
        "            resp = openai_client.embeddings.create(model=model, input=text)\n",
        "            return resp.data[0].embedding\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            sleep_s = (1.8 ** attempt) + 0.1 * attempt\n",
        "            print(f\"[임베딩 재시도 {attempt}/{max_retries}] {e} → {sleep_s:.1f}s 대기\")\n",
        "            time.sleep(sleep_s)\n",
        "    raise RuntimeError(f\"임베딩 생성 실패: {last_err}\")\n",
        "\n",
        "def extract_first_binary_digit(text: str) -> str:\n",
        "    \"\"\"\n",
        "    모델 출력에서 가장 먼저 등장하는 0 또는 1 한 글자만 추출.\n",
        "    없으면 '0'으로 보수적 판정.\n",
        "    \"\"\"\n",
        "    m = re.search(r\"[01]\", text)\n",
        "    return m.group(0) if m else \"0\"\n"
      ],
      "metadata": {
        "id": "vdCajuzUuQQK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 로드"
      ],
      "metadata": {
        "id": "Tc-DrDGrudLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Clone repo via git + git-lfs, then load target files\n",
        "# =========================================================\n",
        "import os, json, subprocess, shlex, tempfile, sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# ---------- 사용자 설정 ----------\n",
        "# 1) GitHub 토큰: 비공개 리포/LFS 권한이 필요하면 넣으세요. 공개라면 빈 문자열 가능\n",
        "GITHUB_TOKEN = \"\"  # 예: \"ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
        "\n",
        "# 2) 읽을 대상들 (URL에서 구조만 추출하여 명시)\n",
        "REPO_OWNER  = \"beefed-up-geek\"\n",
        "REPO_NAME   = \"compliance_checking\"\n",
        "REPO_REF    = \"main\"  # branch or tag or commit\n",
        "# 이벤트 JSON (LFS 파일)\n",
        "EVENTIC_REL_PATH = \"environments/GDPR-13/eventic_with_embedding.json\"\n",
        "# TSV (원래 raw URL이지만, 리포 경로와 동일하므로 로컬에서 읽음)\n",
        "TSV_REL_PATH     = \"environments/GDPR-13/data/original/sample.tsv\"\n",
        "\n",
        "# ---------- 유틸 ----------\n",
        "def _run(cmd: str, cwd: str | None = None, check: bool = True) -> subprocess.CompletedProcess:\n",
        "    \"\"\"Run shell command, raising with readable message on failure.\"\"\"\n",
        "    p = subprocess.run(\n",
        "        cmd if isinstance(cmd, list) else shlex.split(cmd),\n",
        "        cwd=cwd,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        text=True,\n",
        "    )\n",
        "    if check and p.returncode != 0:\n",
        "        msg = (\n",
        "            f\"[CMD FAIL] {cmd}\\n\"\n",
        "            f\"[STDOUT]\\n{p.stdout}\\n\"\n",
        "            f\"[STDERR]\\n{p.stderr}\\n\"\n",
        "        )\n",
        "        raise RuntimeError(msg)\n",
        "    return p\n",
        "\n",
        "def _ensure_git_installed():\n",
        "    try:\n",
        "        _run(\"git --version\", check=True)\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(\"git이 필요합니다. 환경에 git을 설치해 주세요.\") from e\n",
        "\n",
        "def _ensure_git_lfs_installed(auto_install: bool = True):\n",
        "    try:\n",
        "        _run(\"git lfs version\", check=True)\n",
        "        return\n",
        "    except Exception:\n",
        "        if not auto_install:\n",
        "            raise RuntimeError(\"git-lfs가 필요합니다. 설치 후 다시 시도하세요.\")\n",
        "        # 시도: Debian/Ubuntu 계열\n",
        "        print(\"[INFO] git-lfs가 없어 설치를 시도합니다 (Debian/Ubuntu 계열).\")\n",
        "        try:\n",
        "            _run(\"sudo apt-get update\", check=True)\n",
        "            _run(\"sudo apt-get install -y git-lfs\", check=True)\n",
        "            _run(\"git lfs install\", check=True)\n",
        "            print(\"[INFO] git-lfs 설치 완료.\")\n",
        "            return\n",
        "        except Exception as e:\n",
        "            # Colab 등 sudo 없는 환경에서 대안: 패키지 미지원 시 수동 설치가 필요할 수 있음\n",
        "            print(\"[WARN] 자동 설치 실패. 환경에 맞게 git-lfs를 수동 설치해야 할 수 있습니다.\")\n",
        "            # 그래도 한 번 더 시도\n",
        "            try:\n",
        "                _run(\"git lfs install\", check=True)\n",
        "                return\n",
        "            except Exception:\n",
        "                raise RuntimeError(\"git-lfs 설치가 필요합니다. 수동 설치 후 다시 실행하세요.\") from e\n",
        "\n",
        "def _build_auth_repo_url(owner: str, repo: str, token: str | None) -> str:\n",
        "    \"\"\"\n",
        "    인증이 필요한 경우 토큰을 URL에 내장해서 https 클론.\n",
        "    Github는 'x-access-token:<token>' 또는 '<token>' 단독도 동작.\n",
        "    \"\"\"\n",
        "    if token:\n",
        "        # 토큰이 로그에 찍히지 않도록 주의! print 금지.\n",
        "        return f\"https://x-access-token:{token}@github.com/{owner}/{repo}.git\"\n",
        "    else:\n",
        "        return f\"https://github.com/{owner}/{repo}.git\"\n",
        "\n",
        "def clone_repo_and_read_files(owner: str, repo: str, ref: str, rel_paths: list[str], token: str | None = None) -> dict[str, str]:\n",
        "    \"\"\"\n",
        "    - git lfs install\n",
        "    - git clone --depth=1 --branch <ref>\n",
        "    - git lfs pull\n",
        "    - files read as text\n",
        "    Returns: {rel_path: file_text}\n",
        "    \"\"\"\n",
        "    _ensure_git_installed()\n",
        "    _ensure_git_lfs_installed(auto_install=True)\n",
        "\n",
        "    results: dict[str, str] = {}\n",
        "    auth_url = _build_auth_repo_url(owner, repo, token)\n",
        "    # 임시 디렉터리에 클론\n",
        "    with tempfile.TemporaryDirectory() as tmpdir:\n",
        "        repo_dir = Path(tmpdir) / \"repo\"\n",
        "\n",
        "        # clone\n",
        "        print(\"[INFO] Cloning repository...\")\n",
        "        _run(f\"git clone --depth=1 --branch {shlex.quote(ref)} {auth_url} repo\", cwd=tmpdir, check=True)\n",
        "\n",
        "        # LFS 활성화(관용적으로 1회)\n",
        "        try:\n",
        "            _run(\"git lfs install\", cwd=str(repo_dir), check=False)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # lfs pull (필요 오브젝트 받기)\n",
        "        print(\"[INFO] Pulling LFS objects (this may take a while)...\")\n",
        "        # 특정 경로만 당기려면: git lfs pull --include=\"path1,path2\"\n",
        "        _run(\"git lfs pull\", cwd=str(repo_dir), check=False)\n",
        "\n",
        "        # 파일 읽기\n",
        "        for rel in rel_paths:\n",
        "            target = repo_dir / rel\n",
        "            if not target.exists():\n",
        "                # lfs checkout 시도 (일부 환경에서 필요)\n",
        "                _run(\"git lfs checkout\", cwd=str(repo_dir), check=False)\n",
        "            if not target.exists():\n",
        "                raise FileNotFoundError(f\"파일을 찾을 수 없습니다: {rel} (ref={ref})\")\n",
        "            # 바이너리일 수도 있으므로 우선 바이너리로 열어보고 디코딩\n",
        "            data = target.read_bytes()\n",
        "            try:\n",
        "                text = data.decode(\"utf-8\")\n",
        "            except UnicodeDecodeError:\n",
        "                # UTF-8이 아니면 'replace'로라도 텍스트화\n",
        "                text = data.decode(\"utf-8\", errors=\"replace\")\n",
        "            results[rel] = text\n",
        "\n",
        "        print(\"[INFO] Clone + LFS + Read OK.\")\n",
        "    return results\n",
        "\n",
        "# ---------- 실행 ----------\n",
        "token = (GITHUB_TOKEN or \"\").strip() or None\n",
        "files_text = clone_repo_and_read_files(\n",
        "    REPO_OWNER, REPO_NAME, REPO_REF,\n",
        "    [EVENTIC_REL_PATH, TSV_REL_PATH],\n",
        "    token=token\n",
        ")\n",
        "\n",
        "# JSON 로드\n",
        "try:\n",
        "    eventic_text = files_text[EVENTIC_REL_PATH]\n",
        "    eventic_data = json.loads(eventic_text)\n",
        "    print(f\"[OK] eventic 항목 수: {len(eventic_data)}\")\n",
        "    print(type(eventic_data[0]), list(eventic_data[0].keys())[:6])\n",
        "except json.JSONDecodeError as e:\n",
        "    # 혹시 포인터 문서나 바이너리였을 경우 확인을 돕기 위한 헤더 일부 출력\n",
        "    print(\"[ERROR] JSON 파싱 실패. 파일 앞부분 미리보기:\")\n",
        "    print(eventic_text[:400])\n",
        "    raise\n",
        "\n",
        "# TSV 로드\n",
        "tsv_text = files_text[TSV_REL_PATH]\n",
        "# BOM 제거\n",
        "if tsv_text.startswith(\"\\ufeff\"):\n",
        "    tsv_text = tsv_text.lstrip(\"\\ufeff\")\n",
        "\n",
        "from io import StringIO\n",
        "df = pd.read_csv(StringIO(tsv_text), sep=\"\\t\", dtype=str).fillna(\"\")\n",
        "print(df.head())\n",
        "print(f\"TSV 샘플 수: {len(df)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22yen8O-ueR8",
        "outputId": "081640f1-1cc7-451f-a1ba-fd58379fc281"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Cloning repository...\n",
            "[INFO] Pulling LFS objects (this may take a while)...\n",
            "[INFO] Clone + LFS + Read OK.\n",
            "[OK] eventic 항목 수: 14\n",
            "<class 'dict'> ['Agent', 'Deontic', 'Action', 'Information', 'Paragraph', 'Condition']\n",
            "  label                                           sentence           filename\n",
            "0     1  You can also choose to add a phone number or p...     www.google.com\n",
            "1     3  to improve and optimize our Services and our p...      www.zynga.com\n",
            "2     3  We process your personal data , such as physic...      bttrm-men.com\n",
            "3     0  Legitimate Interest : We process the following...         narvii.com\n",
            "4     0  Some cookies allow us to make it easier for yo...  www.bolegames.com\n",
            "TSV 샘플 수: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Qwen 모델 로드 (GPU가 있다면 자동 할당)"
      ],
      "metadata": {
        "id": "-U_4C2E01n6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "# pad 토큰 설정(경고 방지)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "print(\"Loaded:\", MODEL_ID)\n",
        "print(\"Model dtype:\", model.dtype)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "43d1f8b676b94b20ab594d6af299c30b",
            "790249fd776e4dceb9027528eac218e9",
            "c7677db32e4640278056651b3081f05e",
            "c1ee22a250a743558cfd93de3a804fac",
            "1305d722bba442a1b8f5dc36a44c1e82",
            "21a0178c8770419c8689e2319987a77c",
            "ed6b0380ae1b49ff883179546ac9a330",
            "f0378e4d66ed4f168442646bcac632bd",
            "e82f75e27d0e4cff823708b9bec6499b",
            "de2dcff09c57447e852504be49f36bd7",
            "c6d3a2ac646e44aa967c0fb872067192"
          ]
        },
        "id": "QDILjKfQ1BJ5",
        "outputId": "6dd101d2-79b6-4716-b6d8-bc64b8c572a5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43d1f8b676b94b20ab594d6af299c30b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: Qwen/Qwen2-7B-Instruct\n",
            "Model dtype: torch.bfloat16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 프롬프트 템플릿"
      ],
      "metadata": {
        "id": "Bg8RCQvg3BSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FEW_SHOT_TEMPLATE = \"\"\"You are a classifier. Your task is to decide whether a given sentence from a website privacy policy is related to GDPR Article 13 information obligations.\n",
        "\n",
        "Output format:\n",
        "- Output ONLY one number: 1 or 0.\n",
        "- 1 = The sentence is related to GDPR Article 13 obligations (information that must be provided).\n",
        "- 0 = The sentence is not related to GDPR Article 13 obligations (irrelevant, generic, or other).\n",
        "\n",
        "Information about GDPR:\n",
        "<information>\n",
        "---\n",
        "\n",
        "Few-shot Examples:\n",
        "\n",
        "Example 1\n",
        "Input: \"Frans Erenstraat 14A\"\n",
        "Output: 0\n",
        "\n",
        "Example 2\n",
        "Input: \"Questions Related to Data Protection and Exercising your Rights\"\n",
        "Output: 0\n",
        "\n",
        "Example 3\n",
        "Input: \"We will process personal data which you transfer to us actively by your entries\"\n",
        "Output: 0\n",
        "\n",
        "Example 4\n",
        "Input: \"Owner contact email : -Email-\"\n",
        "Output: 1\n",
        "\n",
        "Example 5\n",
        "Input: \"Full name of legal entity : Jagex Limited\"\n",
        "Output: 1\n",
        "\n",
        "Example 6\n",
        "Input: \"You can edit or delete your data at any time\"\n",
        "Output: 1\n",
        "\n",
        "Example 7\n",
        "Input: \"Right to Restrict the Processing\"\n",
        "Output: 1\n",
        "\n",
        "Example 8\n",
        "Input: \"Data retention period\"\n",
        "Output: 1\n",
        "\n",
        "---\n",
        "\n",
        "Now classify the following sentence:\n",
        "{sentence}\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "AHUCPnk53EPE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eventic 임베딩 행렬 준비 (코사인 유사도용)"
      ],
      "metadata": {
        "id": "puV-eGAB4zFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def _l2_normalize(mat: np.ndarray, eps: float = 1e-12) -> np.ndarray:\n",
        "    norms = np.linalg.norm(mat, axis=1, keepdims=True)\n",
        "    norms = np.maximum(norms, eps)\n",
        "    return mat / norms\n",
        "\n",
        "# eventic_data에서 embedding 벡터만 추출\n",
        "eventic_items = eventic_data  # 앞 셀에서 로드되어 있다고 가정\n",
        "vecs = []\n",
        "kept_items = []\n",
        "for it in eventic_items:\n",
        "    emb = it.get(\"embedding\")\n",
        "    if isinstance(emb, list) and len(emb) > 0:\n",
        "        vecs.append(emb)\n",
        "        kept_items.append(it)\n",
        "\n",
        "if not vecs:\n",
        "    raise RuntimeError(\"eventic_data에 'embedding' 벡터가 없습니다. eventic_with_embedding.json을 확인하세요.\")\n",
        "\n",
        "E = np.array(vecs, dtype=np.float32)\n",
        "E = _l2_normalize(E)\n",
        "print(f\"[OK] Eventic 임베딩 행렬: shape={E.shape}, 사용 항목 수={len(kept_items)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBjqYsul41Vr",
        "outputId": "2b40ba11-93a0-485c-bcb1-823492c3b452"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Eventic 임베딩 행렬: shape=(14, 3072), 사용 항목 수=14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 임베딩 & 매칭 함수 (Top‑K / THRESHOLD None 처리 로직 포함)"
      ],
      "metadata": {
        "id": "vgTGwEoI45_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from typing import List, Dict, Any, Tuple\n",
        "\n",
        "def get_embedding(text: str, model: str = EMBED_MODEL, max_retries: int = 5) -> List[float]:\n",
        "    text = (text or \"\").strip()\n",
        "    last_err = None\n",
        "    for attempt in range(1, max_retries + 1):\n",
        "        try:\n",
        "            resp = openai_client.embeddings.create(model=model, input=text)\n",
        "            return resp.data[0].embedding\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            time.sleep((1.6 ** attempt) + 0.1 * attempt)\n",
        "    raise RuntimeError(f\"임베딩 생성 실패: {last_err}\")\n",
        "\n",
        "def search_relevant_clauses(\n",
        "    query_text: str,\n",
        "    top_k: int | None = TOP_K,\n",
        "    threshold: float | None = THRESHOLD\n",
        ") -> List[Tuple[float, Dict[str, Any]]]:\n",
        "    \"\"\"\n",
        "    반환: [(similarity, eventic_item), ...]\n",
        "    규칙:\n",
        "      - top_k is None & threshold is None  -> [] (아무 데이터도 추가하지 않음)\n",
        "      - top_k is None & threshold is not None -> 임계값 이상 모두 반환 (유사도 내림차순)\n",
        "      - top_k is not None & threshold is None -> 상위 top_k만 반환 (유사도 내림차순)\n",
        "      - 둘 다 지정 -> 임계값 이상에서 상위 top_k만 반환\n",
        "    \"\"\"\n",
        "    if top_k is None and threshold is None:\n",
        "        return []\n",
        "\n",
        "    q = np.array(get_embedding(query_text), dtype=np.float32)\n",
        "    q = q / (np.linalg.norm(q) + 1e-12)\n",
        "    sims = E @ q  # 코사인 유사도\n",
        "\n",
        "    # 공통: 유사도 높은 순 정렬 인덱스\n",
        "    order = np.argsort(-sims)\n",
        "\n",
        "    matches = []\n",
        "    if top_k is None and threshold is not None:\n",
        "        # 임계값 이상 모두\n",
        "        for idx in order:\n",
        "            s = float(sims[idx])\n",
        "            if s < threshold:\n",
        "                break\n",
        "            matches.append((s, kept_items[idx]))\n",
        "        return matches\n",
        "\n",
        "    if top_k is not None and threshold is None:\n",
        "        # 상위 top_k\n",
        "        k = max(0, int(top_k))\n",
        "        for idx in order[:k]:\n",
        "            matches.append((float(sims[idx]), kept_items[idx]))\n",
        "        return matches\n",
        "\n",
        "    # 둘 다 지정된 경우: 임계값 이상 중 상위 top_k\n",
        "    k = max(0, int(top_k))\n",
        "    for idx in order:\n",
        "        s = float(sims[idx])\n",
        "        if s < threshold:\n",
        "            break\n",
        "        matches.append((s, kept_items[idx]))\n",
        "        if len(matches) >= k:\n",
        "            break\n",
        "    return matches\n"
      ],
      "metadata": {
        "id": "vnoIPOPy47wb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \\<information\\> 블록 생성"
      ],
      "metadata": {
        "id": "IRy4oQPi48-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_information_block(items: list[dict]) -> str:\n",
        "    \"\"\"\n",
        "    items: [item_dict, ...]\n",
        "    \"\"\"\n",
        "    if not items:\n",
        "        return \"\"\n",
        "    lines = []\n",
        "    for r in items:\n",
        "        lines.append(\n",
        "            f\"paragraph [{r.get('Paragraph','')}] \"\n",
        "            f\"{r.get('Agent','')} \"\n",
        "            f\"{r.get('Deontic','')} \"\n",
        "            f\"{r.get('Action','')} \"\n",
        "            f\"{r.get('Information','')} \"\n",
        "            f\"{r.get('Condition','')}\"\n",
        "        )\n",
        "    return \"\\n\".join(lines)\n",
        "\n"
      ],
      "metadata": {
        "id": "_EO9fjOA5AQu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 분류 프롬프트 & Qwen 추론 (이미 로드되어 있으면 재사용)"
      ],
      "metadata": {
        "id": "uKm3iKXB5DFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import torch\n",
        "\n",
        "# 이미 tokenizer/model을 로드했다면 재사용\n",
        "try:\n",
        "    tokenizer, model\n",
        "except NameError:\n",
        "    from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "    MODEL_ID = \"Qwen/Qwen2-7B-Instruct\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True, trust_remote_code=True)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL_ID,\n",
        "        torch_dtype=\"auto\",\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        "    )\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "    print(\"Loaded:\", MODEL_ID, \"| dtype:\", model.dtype)\n",
        "\n",
        "GEN_ARGS = dict(max_new_tokens=8, do_sample=False, temperature=0.0)\n",
        "\n",
        "def _extract_first_binary_digit(text: str) -> str:\n",
        "    m = re.search(r\"[01]\", text)\n",
        "    return m.group(0) if m else \"0\"\n",
        "\n",
        "def classify_sentence_with_qwen(sentence: str, information_block: str) -> tuple[str, str]:\n",
        "    prompt = FEW_SHOT_TEMPLATE.format(sentence=sentence)\n",
        "    prompt = prompt.replace(\"<information>\", (information_block if information_block else \"N/A\"))\n",
        "\n",
        "    try:\n",
        "        # Qwen 채팅 템플릿\n",
        "        chat = [{\"role\": \"user\", \"content\": prompt}]\n",
        "        text = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
        "    except Exception:\n",
        "        text = prompt\n",
        "\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(**inputs, **GEN_ARGS)\n",
        "    gen = tokenizer.decode(out[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
        "    return _extract_first_binary_digit(gen), gen\n"
      ],
      "metadata": {
        "id": "u5kRr2Du5FMV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 하나만 처리해보기"
      ],
      "metadata": {
        "id": "E2delzgC5gDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_row = df.iloc[0]\n",
        "sample_sentence = str(sample_row[\"sentence\"])\n",
        "\n",
        "sample_matches = search_relevant_clauses(sample_sentence, top_k=TOP_K, threshold=THRESHOLD)\n",
        "sample_only_items = [it for _, it in sample_matches]\n",
        "sample_info_block = build_information_block(sample_only_items)\n",
        "\n",
        "pred, raw = classify_sentence_with_qwen(sample_sentence, sample_info_block)\n",
        "\n",
        "# 라벨 이진화\n",
        "try:\n",
        "    rli = int(str(sample_row[\"label\"]).strip())\n",
        "except Exception:\n",
        "    rli = 0\n",
        "gold_bin = 0 if rli == 0 else 1\n",
        "\n",
        "print(\"Sentence:\", sample_sentence)\n",
        "print(\"Gold (bin):\", gold_bin, \"| Pred:\", pred)\n",
        "print(\"\\n--- information block ---\\n\", sample_info_block if sample_info_block else \"(첨부 없음)\")\n",
        "print(\"\\n--- raw model output ---\\n\", raw)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bp_WJkFm5hti",
        "outputId": "7bca93eb-e72e-452c-9e7f-a094bd63ad49"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: You can also choose to add a phone number or payment information to your account \n",
            "Gold (bin): 1 | Pred: 0\n",
            "\n",
            "--- information block ---\n",
            " paragraph [2(f)] Controller shall provide existence of automated decision-making including profiling, meaningful information about the logic involved, and the significance and envisaged consequences only if automated decision-making including profiling under Article 22(1) and (4) exists, at the time obtained\n",
            "paragraph [4] Controller need not provide information required under paragraphs 1 to 3 insofar as the data subject already has the information\n",
            "paragraph [2(c)] Controller shall provide right to withdraw consent at any time only if processing is based on consent under Article 6(1)(a) or Article 9(2)(a), at the time obtained\n",
            "paragraph [1(d)] Controller shall provide legitimate interests pursued where processing is based on Article 6(1)(f) only if legal basis is Article 6(1)(f), at the time obtained\n",
            "paragraph [2(e)] Controller shall provide whether the provision of personal data is a statutory or contractual requirement or a requirement necessary to enter into a contract, as well as the consequences of failing to provide such data when personal data are collected from the data subject, at the time obtained\n",
            "paragraph [1(a)] Controller shall provide identity and contact details of the controller and of the controller's representative where applicable when personal data are collected from the data subject, at the time obtained\n",
            "paragraph [1(c)] Controller shall provide purposes of the processing and the legal basis for the processing when personal data are collected from the data subject, at the time obtained\n",
            "paragraph [2(a)] Controller shall provide period for which the personal data will be stored or the criteria used to determine that period when personal data are collected from the data subject, at the time obtained\n",
            "\n",
            "--- raw model output ---\n",
            " 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전체 분류 루프 + Accuracy / MCC (저장 없음)"
      ],
      "metadata": {
        "id": "hGKkjDUn5M2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, matthews_corrcoef\n",
        "from tqdm import tqdm\n",
        "\n",
        "# df에는 최소 'sentence'와 'label' 컬럼이 있어야 합니다.\n",
        "if \"sentence\" not in df.columns:\n",
        "    raise ValueError(\"df에 'sentence' 컬럼이 필요합니다.\")\n",
        "if \"label\" not in df.columns:\n",
        "    raise ValueError(\"df에 'label' 컬럼이 필요합니다.\")\n",
        "\n",
        "pred_labels: list[int] = []\n",
        "gold_labels: list[int] = []\n",
        "info_blocks: list[str] = []\n",
        "raw_outputs: list[str] = []\n",
        "\n",
        "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Classifying\"):\n",
        "    sent = str(row[\"sentence\"])\n",
        "\n",
        "    # 관련 조항 매칭 (TOP_K / THRESHOLD None 로직 반영된 함수)\n",
        "    matches = search_relevant_clauses(sent, top_k=TOP_K, threshold=THRESHOLD)\n",
        "    # build_information_block는 Dict 리스트만 받도록 구현했다면 item만 추출\n",
        "    only_items = [it for _, it in matches]\n",
        "    info_block = build_information_block(only_items)\n",
        "    info_blocks.append(info_block)\n",
        "\n",
        "    # Qwen 분류\n",
        "    pred, raw = classify_sentence_with_qwen(sent, info_block)\n",
        "    pred_labels.append(int(pred))\n",
        "    raw_outputs.append(raw)\n",
        "\n",
        "    # --- 라벨 이진화 규칙: 0이면 0, 아니면 1 ---\n",
        "    raw_label = row[\"label\"]\n",
        "    try:\n",
        "        rli = int(str(raw_label).strip())\n",
        "    except Exception:\n",
        "        # 숫자가 아니면 연관 있음(=1)으로 취급할지, 0으로 둘지 정책 필요\n",
        "        # 여기서는 안전하게 '연관 없음'을 0으로 기본 처리\n",
        "        rli = 0\n",
        "    gold_bin = 0 if rli == 0 else 1\n",
        "    gold_labels.append(gold_bin)\n",
        "\n",
        "# 지표\n",
        "acc = accuracy_score(gold_labels, pred_labels)\n",
        "mcc = matthews_corrcoef(gold_labels, pred_labels)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"MCC: {mcc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H93jBJX45O-w",
        "outputId": "acc2345b-df95-441d-8496-7a9cf39dff8a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Classifying:   0%|          | 0/200 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:   0%|          | 1/200 [00:00<01:46,  1.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:   1%|          | 2/200 [00:00<01:19,  2.48it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:   2%|▏         | 3/200 [00:01<01:12,  2.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:   2%|▏         | 4/200 [00:01<01:12,  2.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:   2%|▎         | 5/200 [00:01<01:11,  2.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:   3%|▎         | 6/200 [00:02<01:15,  2.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:   4%|▎         | 7/200 [00:02<01:06,  2.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:   4%|▍         | 8/200 [00:03<01:14,  2.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:   4%|▍         | 9/200 [00:03<01:13,  2.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:   5%|▌         | 10/200 [00:03<01:09,  2.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:   6%|▌         | 11/200 [00:04<01:10,  2.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:   6%|▌         | 12/200 [00:04<01:08,  2.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:   6%|▋         | 13/200 [00:04<01:10,  2.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:   7%|▋         | 14/200 [00:05<01:03,  2.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:   8%|▊         | 15/200 [00:05<01:06,  2.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:   8%|▊         | 16/200 [00:06<01:39,  1.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:   8%|▊         | 17/200 [00:06<01:25,  2.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:   9%|▉         | 18/200 [00:07<01:16,  2.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  10%|▉         | 19/200 [00:07<01:10,  2.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  10%|█         | 20/200 [00:07<01:05,  2.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  10%|█         | 21/200 [00:08<01:10,  2.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  11%|█         | 22/200 [00:08<01:20,  2.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  12%|█▏        | 23/200 [00:09<01:14,  2.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  12%|█▏        | 24/200 [00:09<01:16,  2.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  12%|█▎        | 25/200 [00:10<01:12,  2.40it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  13%|█▎        | 26/200 [00:10<01:05,  2.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  14%|█▎        | 27/200 [00:10<01:06,  2.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  14%|█▍        | 28/200 [00:11<01:09,  2.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  14%|█▍        | 29/200 [00:11<01:10,  2.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  15%|█▌        | 30/200 [00:11<01:03,  2.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  16%|█▌        | 31/200 [00:12<01:06,  2.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  16%|█▌        | 32/200 [00:12<01:12,  2.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  16%|█▋        | 33/200 [00:13<01:09,  2.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  17%|█▋        | 34/200 [00:13<01:08,  2.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  18%|█▊        | 35/200 [00:13<01:01,  2.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  18%|█▊        | 36/200 [00:14<00:59,  2.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  18%|█▊        | 37/200 [00:14<00:58,  2.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  19%|█▉        | 38/200 [00:14<00:57,  2.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  20%|█▉        | 39/200 [00:15<00:56,  2.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  20%|██        | 40/200 [00:15<00:58,  2.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  20%|██        | 41/200 [00:16<01:00,  2.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  21%|██        | 42/200 [00:16<01:20,  1.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  22%|██▏       | 43/200 [00:17<01:13,  2.14it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  22%|██▏       | 44/200 [00:17<01:08,  2.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  22%|██▎       | 45/200 [00:18<01:18,  1.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  23%|██▎       | 46/200 [00:18<01:11,  2.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  24%|██▎       | 47/200 [00:18<01:05,  2.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  24%|██▍       | 48/200 [00:19<01:02,  2.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  24%|██▍       | 49/200 [00:19<01:00,  2.48it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  25%|██▌       | 50/200 [00:20<01:03,  2.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  26%|██▌       | 51/200 [00:20<00:59,  2.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  26%|██▌       | 52/200 [00:21<01:00,  2.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  26%|██▋       | 53/200 [00:21<00:56,  2.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  27%|██▋       | 54/200 [00:21<00:53,  2.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  28%|██▊       | 55/200 [00:22<00:54,  2.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  28%|██▊       | 56/200 [00:22<00:52,  2.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  28%|██▊       | 57/200 [00:22<00:52,  2.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  29%|██▉       | 58/200 [00:23<00:50,  2.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  30%|██▉       | 59/200 [00:23<00:47,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  30%|███       | 60/200 [00:23<00:50,  2.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  30%|███       | 61/200 [00:24<00:54,  2.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  31%|███       | 62/200 [00:24<00:50,  2.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  32%|███▏      | 63/200 [00:24<00:51,  2.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  32%|███▏      | 64/200 [00:25<00:46,  2.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  32%|███▎      | 65/200 [00:25<00:53,  2.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  33%|███▎      | 66/200 [00:26<00:51,  2.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  34%|███▎      | 67/200 [00:26<00:50,  2.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  34%|███▍      | 68/200 [00:26<00:48,  2.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  34%|███▍      | 69/200 [00:27<00:51,  2.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  35%|███▌      | 70/200 [00:27<00:56,  2.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  36%|███▌      | 71/200 [00:28<00:55,  2.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  36%|███▌      | 72/200 [00:28<00:52,  2.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  36%|███▋      | 73/200 [00:28<00:51,  2.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  37%|███▋      | 74/200 [00:29<00:53,  2.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  38%|███▊      | 75/200 [00:29<00:53,  2.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  38%|███▊      | 76/200 [00:30<00:47,  2.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  38%|███▊      | 77/200 [00:30<00:45,  2.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  39%|███▉      | 78/200 [00:30<00:44,  2.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  40%|███▉      | 79/200 [00:31<00:42,  2.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  40%|████      | 80/200 [00:31<00:46,  2.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  40%|████      | 81/200 [00:32<00:46,  2.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  41%|████      | 82/200 [00:32<00:47,  2.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  42%|████▏     | 83/200 [00:32<00:42,  2.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  42%|████▏     | 84/200 [00:33<00:41,  2.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  42%|████▎     | 85/200 [00:33<00:43,  2.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  43%|████▎     | 86/200 [00:33<00:39,  2.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  44%|████▎     | 87/200 [00:34<00:49,  2.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  44%|████▍     | 88/200 [00:34<00:44,  2.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  44%|████▍     | 89/200 [00:35<00:43,  2.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  45%|████▌     | 90/200 [00:35<00:40,  2.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  46%|████▌     | 91/200 [00:35<00:39,  2.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  46%|████▌     | 92/200 [00:36<00:37,  2.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  46%|████▋     | 93/200 [00:36<00:36,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  47%|████▋     | 94/200 [00:36<00:42,  2.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  48%|████▊     | 95/200 [00:37<00:41,  2.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  48%|████▊     | 96/200 [00:37<00:38,  2.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  48%|████▊     | 97/200 [00:37<00:36,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  49%|████▉     | 98/200 [00:38<00:38,  2.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  50%|████▉     | 99/200 [00:38<00:39,  2.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  50%|█████     | 100/200 [00:39<00:35,  2.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  50%|█████     | 101/200 [00:39<00:33,  2.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  51%|█████     | 102/200 [00:39<00:38,  2.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  52%|█████▏    | 103/200 [00:40<00:36,  2.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  52%|█████▏    | 104/200 [00:40<00:36,  2.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  52%|█████▎    | 105/200 [00:40<00:33,  2.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  53%|█████▎    | 106/200 [00:41<00:34,  2.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  54%|█████▎    | 107/200 [00:41<00:31,  2.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  54%|█████▍    | 108/200 [00:41<00:30,  2.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  55%|█████▍    | 109/200 [00:42<00:31,  2.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  55%|█████▌    | 110/200 [00:42<00:34,  2.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  56%|█████▌    | 111/200 [00:43<00:34,  2.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  56%|█████▌    | 112/200 [00:43<00:33,  2.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  56%|█████▋    | 113/200 [00:43<00:30,  2.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  57%|█████▋    | 114/200 [00:44<00:29,  2.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  57%|█████▊    | 115/200 [00:44<00:30,  2.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  58%|█████▊    | 116/200 [00:44<00:27,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  58%|█████▊    | 117/200 [00:45<00:26,  3.14it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  59%|█████▉    | 118/200 [00:45<00:30,  2.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  60%|█████▉    | 119/200 [00:46<00:31,  2.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  60%|██████    | 120/200 [00:46<00:29,  2.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  60%|██████    | 121/200 [00:46<00:27,  2.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  61%|██████    | 122/200 [00:46<00:27,  2.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  62%|██████▏   | 123/200 [00:47<00:26,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  62%|██████▏   | 124/200 [00:47<00:24,  3.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  62%|██████▎   | 125/200 [00:47<00:24,  3.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  63%|██████▎   | 126/200 [00:48<00:24,  2.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  64%|██████▎   | 127/200 [00:48<00:24,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  64%|██████▍   | 128/200 [00:48<00:24,  2.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  64%|██████▍   | 129/200 [00:49<00:22,  3.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  65%|██████▌   | 130/200 [00:49<00:22,  3.09it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  66%|██████▌   | 131/200 [00:49<00:23,  2.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  66%|██████▌   | 132/200 [00:50<00:22,  2.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  66%|██████▋   | 133/200 [00:50<00:23,  2.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  67%|██████▋   | 134/200 [00:50<00:21,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  68%|██████▊   | 135/200 [00:51<00:22,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  68%|██████▊   | 136/200 [00:51<00:22,  2.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  68%|██████▊   | 137/200 [00:52<00:25,  2.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  69%|██████▉   | 138/200 [00:52<00:25,  2.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  70%|██████▉   | 139/200 [00:52<00:24,  2.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  70%|███████   | 140/200 [00:53<00:23,  2.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  70%|███████   | 141/200 [00:53<00:22,  2.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  71%|███████   | 142/200 [00:54<00:21,  2.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  72%|███████▏  | 143/200 [00:54<00:20,  2.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  72%|███████▏  | 144/200 [00:54<00:18,  3.01it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  72%|███████▎  | 145/200 [00:55<00:18,  2.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  73%|███████▎  | 146/200 [00:55<00:23,  2.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  74%|███████▎  | 147/200 [00:56<00:21,  2.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  74%|███████▍  | 148/200 [00:56<00:20,  2.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  74%|███████▍  | 149/200 [00:56<00:19,  2.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  75%|███████▌  | 150/200 [00:57<00:18,  2.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  76%|███████▌  | 151/200 [00:57<00:18,  2.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  76%|███████▌  | 152/200 [00:57<00:16,  2.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  76%|███████▋  | 153/200 [00:58<00:17,  2.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  77%|███████▋  | 154/200 [00:58<00:16,  2.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  78%|███████▊  | 155/200 [00:58<00:15,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  78%|███████▊  | 156/200 [00:59<00:14,  2.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  78%|███████▊  | 157/200 [00:59<00:14,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  79%|███████▉  | 158/200 [00:59<00:13,  3.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  80%|███████▉  | 159/200 [01:00<00:13,  3.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  80%|████████  | 160/200 [01:00<00:14,  2.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  80%|████████  | 161/200 [01:00<00:14,  2.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  81%|████████  | 162/200 [01:01<00:13,  2.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  82%|████████▏ | 163/200 [01:01<00:12,  2.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  82%|████████▏ | 164/200 [01:02<00:12,  2.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  82%|████████▎ | 165/200 [01:02<00:12,  2.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  83%|████████▎ | 166/200 [01:02<00:11,  2.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  84%|████████▎ | 167/200 [01:03<00:11,  2.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  84%|████████▍ | 168/200 [01:03<00:10,  2.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  84%|████████▍ | 169/200 [01:03<00:10,  2.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  85%|████████▌ | 170/200 [01:04<00:10,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  86%|████████▌ | 171/200 [01:04<00:10,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  86%|████████▌ | 172/200 [01:04<00:09,  2.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  86%|████████▋ | 173/200 [01:05<00:09,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  87%|████████▋ | 174/200 [01:05<00:08,  3.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  88%|████████▊ | 175/200 [01:05<00:08,  3.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  88%|████████▊ | 176/200 [01:06<00:07,  3.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  88%|████████▊ | 177/200 [01:06<00:07,  3.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  89%|████████▉ | 178/200 [01:06<00:07,  2.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  90%|████████▉ | 179/200 [01:07<00:07,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  90%|█████████ | 180/200 [01:07<00:06,  2.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  90%|█████████ | 181/200 [01:07<00:06,  3.09it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  91%|█████████ | 182/200 [01:08<00:05,  3.01it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  92%|█████████▏| 183/200 [01:08<00:06,  2.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  92%|█████████▏| 184/200 [01:08<00:06,  2.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  92%|█████████▎| 185/200 [01:09<00:05,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  93%|█████████▎| 186/200 [01:09<00:05,  2.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  94%|█████████▎| 187/200 [01:09<00:04,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  94%|█████████▍| 188/200 [01:10<00:04,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  94%|█████████▍| 189/200 [01:10<00:03,  2.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  95%|█████████▌| 190/200 [01:11<00:03,  2.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  96%|█████████▌| 191/200 [01:11<00:03,  2.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  96%|█████████▌| 192/200 [01:11<00:03,  2.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  96%|█████████▋| 193/200 [01:12<00:02,  2.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  97%|█████████▋| 194/200 [01:12<00:02,  2.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  98%|█████████▊| 195/200 [01:12<00:01,  2.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  98%|█████████▊| 196/200 [01:13<00:01,  2.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  98%|█████████▊| 197/200 [01:13<00:01,  2.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying:  99%|█████████▉| 198/200 [01:13<00:00,  2.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying: 100%|█████████▉| 199/200 [01:14<00:00,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Classifying: 100%|██████████| 200/200 [01:14<00:00,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6150\n",
            "MCC: 0.2436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}